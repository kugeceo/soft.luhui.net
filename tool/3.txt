Hugging Face 部署指南（2025 更新）



鲁虺/撰稿





### Hugging Face 部署指南（2025 更新）

Hugging Face 是开源 AI 模型的首选平台，支持多种部署方式，包括 Spaces（适合快速构建交互式 demo）和 Inference Endpoints（适合生产级 API 服务）。以下基于官方文档，提供详细步骤指南。部署前，确保您有 Hugging Face 账户，并根据需求选择免费/付费硬件。注意：免费选项有使用限制，如闲置时休眠。

#### 1. 使用 Spaces 部署（交互式 ML Demo）
Spaces 允许您像 Git 仓库一样管理代码，支持 Gradio、Streamlit 或 Docker SDK，适合模型可视化演示。每个提交会自动重建并重启应用。

**前提条件**：
- Hugging Face 账户。
- Git 工具（可选，本地克隆仓库）。

**步骤**：
1. **创建新 Space**：访问 https://huggingface.co/spaces，点击“Create new Space”。选择名称、许可证、可见性（公开/私有）和 SDK（推荐 Gradio 用于 ML demo）。
2. **添加代码和文件**：使用 Git 克隆仓库（HTTPS 或 SSH），编写代码（如 Gradio app.py），然后推送提交。自动触发部署。
3. **配置环境变量和密钥**：在 Space 设置页面添加变量（公开配置）或 secrets（敏感信息，如 API 密钥）。在代码中使用 `os.getenv('KEY')` 访问。避免硬编码密钥，以防安全警告。
4. **选择硬件和存储**：在设置中升级硬件（默认免费 CPU Basic）。添加持久存储以保存数据。
5. **部署并管理**：提交后自动部署。测试后，可暂停/恢复，或复制 Space 作为模板。链接模型/数据集：在 README.md 中添加 `models: [model-id]` 以自动展示。

**硬件和存储选项**（部分示例，详见定价页）：
| 硬件类型          | GPU 内存 | CPU    | 内存   | 磁盘    | 小时价格 |
|-------------------|----------|--------|--------|---------|----------|
| CPU Basic (默认) | -       | 2 vCPU | 16 GB | 50 GB  | 免费    |
| Nvidia T4 - small| 16 GB   | 4 vCPU | 15 GB | 50 GB  | $0.60   |
| Nvidia A10G - large | 24 GB | 12 vCPU| 46 GB | 200 GB | $3.15   |

**存储选项**：
| 存储层级 | 大小          | 持久化 | 月费   |
|----------|---------------|--------|--------|
| Ephemeral (默认) | 50 GB     | 否    | 免费   |
| Small    | +20 GB      | 是    | $5     |

**提示**：
- 免费 Space 闲置后休眠；付费硬件持续运行。
- 申请社区 GPU 资助用于创新项目。
- 适合初学者：用 Gradio 快速构建模型交互界面。

#### 2. 使用 Inference Endpoints 部署（生产 API 服务）
Inference Endpoints 提供安全、可扩展的 API 端点，支持 Transformers、Diffusers 等模型，适合高负载推理。端点默认私有，使用 TLS/SSL 加密。

**前提条件**：
- Hugging Face 账户并登录 https://endpoints.huggingface.co。
- 在 https://huggingface.co/settings/billing 设置支付方式。

**支持模型**：
- 模型目录支持热门模型（如 meta-llama/Llama-3.2-3B-Instruct），按任务、硬件过滤。

**硬件选项**：
- 示例：Nvidia L4（推荐，性价比高）。目录中预选默认配置。

**成本**：
- 按硬件过滤显示价格；闲置 1 小时后自动缩减至零（不计费）。具体详见 UI。

**步骤**：
1. **访问 UI**：登录 https://endpoints.huggingface.co，点击“New” 创建端点，进入模型目录。
2. **选择模型**：搜索模型（如“llama-3.2-3b”），点击卡片选中。
3. **配置硬件**：审查预选默认（如 Nvidia L4），无需修改（除非自定义）。端点默认 1 小时闲置缩减。
4. **创建端点**：点击“Create Endpoint”，初始化需 3-5 分钟。启用浏览器通知以获运行状态提醒。
5. **测试端点**：运行后，使用 Playground 视觉测试，或复制代码片段发送请求。配置访问令牌（在 Hugging Face “App Tokens” 生成）进行认证。
6. **管理端点**：测试后暂停、删除或缩减。数据传输加密。

**提示**：
- 使用目录预选配置以优化性能。
- 端点私有：始终需令牌认证。
- 扩展：支持自动缩放，适合生产环境。

#### 总体建议
- **选择方式**：Spaces 适合原型和分享，Inference Endpoints 适合 API 集成。
- **2025 趋势**：集成 Azure/Google Cloud 等云服务，实现一键部署。
- **资源**：参考官方文档或社区论坛调试问题。








驾驭网络，共创神奇，答疑解惑，富贵勿忘，济民强国，助我发展！

## 捐助打赏作者

手机如何扫码：

![打赏作者](http://flash.luhui.net/images/zhifu.png)
[img]http://flash.luhui.net/images/zhifu.png[/img]

① 保存上面二维码图片　② 打开微信、支付宝、手机qq、“扫一扫”　③ 点击右下脚图标　④ 选择刚才保存的图片

paypal贝宝支付：

[http://paypal.me/guanfu](http://paypal.me/guanfu)


感谢每一位捐赠者，我一直在坚持不懈地努力和创新，不断精心打磨产品，并坚持完全免费，我走过的每一步、开发的每一个功能，离不开那些默默支持我的热心用户，
大家的每一份捐赠和建议，都是我做的更好、走的更远最大的支持和动力！感谢大家，感谢有你，与你相遇好幸运！

您的捐赠将会用于：

①  支付服务器、域名费用，有时候百分之九十的问题是没钱烧了。
②  软件测试更新，分享更丰富的源码数据、工具，推荐更友好的用户界面设计。
③  撰写发布更多心得文章，保证作者的官网一直免费为大家提供服务。

